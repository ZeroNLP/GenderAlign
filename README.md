# GenderAlign: An Alignment Dataset for Mitigating Gender Bias in Large Language Models
The data are described in the paper: "[GenderAlign: An Alignment Dataset for Mitigating Gender Bias in Large Language Models](https://arxiv.org/abs/2406.13925)". If you find the data useful, please cite the paper. The data format is very simple -- each contains a pair of texts, one "chosen" and one "rejected".
